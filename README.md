## REST
### Лёгкая нагрузка (sanity check): убедиться, что всё работает.
Запустить приложение со следующими ресурсами:
```
docker build -t app_http .
```
```
docker run -p 8000:8000 --cpus="0.708" --memory="133M" -d app_http
```
Запустить нагрузку и после установить символическое число пользователей (например, 5 на 30с)
1. `locust -f tests/performance/rest/locustfile.py`
2.  Перейти по адресу: `http://localhost:8089`

Убедиться, что все отработало успешно

<img width="2612" height="1800" alt="total_requests_per_second_1768743696 912" src="https://github.com/user-attachments/assets/70efdf85-940a-4646-b49f-fb7b79ca81f9" />

### Установка рабочей нагрузки
В качестве рабочей нагрузки было принято значение в 280 rps для установленных ранее ресурсов


<img width="2928" height="1800" alt="total_requests_per_second_1768744392 496" src="https://github.com/user-attachments/assets/877da63f-e866-47a6-bfee-6c7c2b816304" />


Характеристики системы в момент рабочей нагрузки

<img width="1223" height="593" alt="Снимок экрана 2026-01-18 в 16 49 50" src="https://github.com/user-attachments/assets/2c19e341-b8cd-41e2-bb8f-833074743b8a" />

### Стресс-тест (приближение к пику): выявить пределы производительности.

Постепенно увеличим количество пользователей до наступления момента пика (1150 пользователей)

<img width="2928" height="1800" alt="total_requests_per_second_1768748423 055-2" src="https://github.com/user-attachments/assets/1cbf1e71-fa9b-4dfd-9658-9838f475c043" />

Графики перед наступлением пика (видно, что начинается нехватка ресурсов)

<img width="1233" height="768" alt="Снимок экрана 2026-01-09 в 13 08 58" src="https://github.com/user-attachments/assets/db8515b9-33ba-4116-9c7c-55fb7cbd947a" />

### Тест на стабильность
В качестве проверки было взято значение приближенное к пику (800 пользователей, 455 rps)

<img width="2928" height="1800" alt="total_requests_per_second_1768746677 338" src="https://github.com/user-attachments/assets/743ca1a9-2fcf-4bb5-aed4-02cc2aff89b9" />

Заметны скачки по времени ответа а также потребления памяти при длительной нагрузке на значениях близких к пиковой нагрузке, но система еще справляется

<img width="1223" height="593" alt="Снимок экрана 2026-01-18 в 17 23 55" src="https://github.com/user-attachments/assets/5c0c54a8-6abd-49c6-a55c-51ff72ed1c25" />

## gRPC
### Лёгкая нагрузка (sanity check): убедиться, что всё работает.
Аналогично запустим на небольшом количестве пользователей и убедимся, что все отработало

Для начала соберем и запустим образ

```
docker build -t app_grpc .
```
```
docker run -p 50051:50051 --cpus="0.708" --memory="133M" -d app_grpc 
```

Запустим активность пользователей

1. `locust -f tests/performance/grpc/locustfile.py`
2.  Перейти по адресу: `http://localhost:8089`

Убедимся, что все отработало корректно

<img width="2928" height="1800" alt="total_requests_per_second_1768751269 31" src="https://github.com/user-attachments/assets/e580dcc0-e557-499d-a1d3-6f0b4a673b79" />

<img width="1223" height="593" alt="Снимок экрана 2026-01-18 в 18 57 08" src="https://github.com/user-attachments/assets/74331856-8004-4c54-9f4d-7ceb42248c05" />

### Установка рабочей нагрузки
Сразу хочется отметить, что выдерживаемый rps выше, чем у REST, а потребляемые ресурсы меньше

<img width="2928" height="1800" alt="total_requests_per_second_1768752775 088" src="https://github.com/user-attachments/assets/34b29146-1143-49b6-884f-ecf5358c1446" />

<img width="1223" height="593" alt="Снимок экрана 2026-01-18 в 19 16 07" src="https://github.com/user-attachments/assets/ea1c3bac-bec1-4663-928b-5eb1730bf824" />

### Стресс-тест (приближение к пику): выявить пределы производительности.
При 1200 пользователях по сравнению с REST показатели лучше
<img width="2928" height="1800" alt="total_requests_per_second_1768754011 356" src="https://github.com/user-attachments/assets/d29b2c38-fdde-452d-b8d0-904280148bdd" />

<img width="2928" height="1800" alt="total_requests_per_second_1768754011 356" src="https://github.com/user-attachments/assets/a703881b-087d-48f0-b558-30689a3960ba" />

Во время тестирования rps держался примерно в одном диапазоне (возможно уперлись в лимиты передачи по сети)

Был замечен интересный момент при повышении количества пользователей резкий скачок по memory usage, который впоследствии стабилизировался
<img width="1223" height="593" alt="Снимок экрана 2026-01-18 в 20 37 52" src="https://github.com/user-attachments/assets/e761c499-e142-4ab8-8d67-938708c51523" />

График из locust выглядит следующим образом
<img width="2928" height="1800" alt="total_requests_per_second_1768759351 488" src="https://github.com/user-attachments/assets/ccd888ae-39d1-48f2-8d20-3191a505de25" />


### Тест на стабильность
Выбрано значение в 3000 пользователей, иногда проседает rps, значение memory usage держится в одном диапазоне, помещаясь в выделенные ресурсы

<img width="2928" height="1800" alt="total_requests_per_second_1768754011 356" src="https://github.com/user-attachments/assets/400e1d3b-48ad-4baf-a939-db080f6aa88c" />

<img width="1223" height="593" alt="Снимок экрана 2026-01-18 в 20 07 08" src="https://github.com/user-attachments/assets/3f386436-e58c-47e5-814f-1c0524d1e9b1" />


### Выводы: 
1. gRPC демонстрирует более высокую пропускную способность (RPS), чем REST, при одинаковых условиях нагрузки. Это обусловлено использованием бинарного протокола Protocol Buffers и HTTP/2, что снижает накладные расходы на сериализацию и передачу данных по сравнению с REST, использующим текстовый JSON поверх HTTP/1.1.
2. Средняя и хвостовая латентность (p95, p99) у gRPC стабильно ниже. Причина заключается в меньшем размере сообщений, отсутствии затратного JSON-парсинга и более эффективном управлении соединениями в HTTP/2 (multiplexing).
3. REST начинает деградировать при меньшем количестве одновременных пользователей: быстрее растёт latency и появляется больше ошибок. Это связано с большим CPU-overhead на обработку HTTP-заголовков и JSON, а также с менее эффективной моделью работы с соединениями.
4. gRPC дольше сохраняет стабильность при росте нагрузки. До достижения предела ресурсов сервис обрабатывает больше запросов без резкого роста времени ответа, что указывает на более эффективное использование CPU и сети.
5. Нагрузка на сеть у gRPC ниже, так как бинарные сообщения Protocol Buffers существенно компактнее JSON. Это напрямую влияет на throughput и снижает вероятность сетевых задержек при высокой нагрузке.
6. Основное «узкое место» REST в данном эксперименте находится на уровне протокола и сериализации данных, а не в бизнес-логике сервиса. У gRPC это узкое место проявляется позже и связано уже с общими ограничениями вычислительных ресурсов.
7. REST остаётся проще в использовании и отладке, однако в контексте высоконагруженного сервиса проигрывает gRPC по эффективности. gRPC предпочтительнее для внутренних сервисных взаимодействий, где важны низкая латентность и высокая масштабируемость.
8. Результаты эксперимента подтверждают, что выбор протокола напрямую влияет на производительность сервиса даже при одинаковой реализации бизнес-логики и одинаковой тестовой среде.
